#### Importing Pandas package

```python
# import pandas packages and give as an alias pd.
# pd is used as pandas alias convention
import pandas as pd 
```

#### Pandas Series

#### Creating Pandas Series

```python
# pd.Series() used for pandas Series
pd.Series([2,4,5,7,8,"Cat","Bat"])

0      2
1      4
2      5
3      7
4      8
5    Cat
6    Bat
dtype: object
```

```python
# we can add an index to pandas series using index pd.Series([],index=[])
pd.Series([2,4,5,7,8,"Cat","Bat"], index=["a","b","c","d","e","f","g"])

a      2
b      4
c      5
d      7
e      8
f    Cat
g    Bat
dtype: object
```

```python
# we can create a pandas series for the pandas dictionary
pd.Series({"a":"Cat","b":"Bat","c":"Rat","d":"Chat"})

a     Cat
b     Bat
c     Rat
d    Chat
dtype: object
```

```python
# we can check for data type using type()
type(s)

pandas.core.series.Series
```

### **Accessing values inside the pandas series**

```python
my_series=pd.Series([1,2,3,4,"Cat"],index=["a","b","c","d","e"])
my_series

a      1
b      2
c      3
d      4
e    Cat
dtype: object
```

```python
# we can access the values in the pandas series in the same as the list
my_series[0] => 1
```

```python
# we can access the values in the pandas series in the same as the list
my_series[4] => 'Cat'
```

```python
# we can also access the values using the index given in the pandas series
my_series["d"] => 4
```

#### Creating Pandas Data Frame

##### Using Dictionaries
```python
# Dictionary
d = {"Name":["Sam","Jane","Kate","Jhon"],"Age":[23,24,43,24]}
df=pd.DataFrame(d)
df

Name	Age
0	Sam	23
1	Jane	24
2	Kate	43
3	Jhon	24

```

##### Using Numpy array
```python
arr=np.array([[12,25],[12,34],[45,34]])
df2 = pd.DataFrame(arr,columns=["Col1","Col2"])
df2

Col1	Col2
0	12	25
1	12	34
2	45	34
```

```python
arr1 = np.array([[23,12],[33,45],[45,34],[34,35]])
df3 = pd.DataFrame(arr1,columns=["Col1","Col2"])
df3

Col1	Col2
0	23	12
1	33	45
2	45	34
3	34	35
```

##### Using Pandas series
```python
my_series=pd.Series([1,2,3,4,7],index=["a","b","c","d","e"])
# we can change Pandas series to Data fram by using .to_frame()
df4=my_series.to_frame()
df4

0
a	1
b	2
c	3
d	4
e	7
```

```python
my_series1=pd.Series([1,2,3,4,7],index=["a","b","c","d","e"])
my_series2=pd.Series([6,5,7,8,2],index=["a","b","c","d","e"])

# we can combine two Pandas series by using pd.concat() but the catch is to same index
pd.concat([my_series1,my_series2],axis=1)

0	1
a	1	6
b	2	5
c	3	7
d	4	8
e	7	2
```

##### Creating data frames using CSV files
```python
## Loading the csv dataset
df5 = pd.read_csv("D:\\Studies\\Workshops\\Datascience Workshop\\Studies\\Dataset\\iris.csv")
df5
```

#### Pandas operations

##### Top Values of dataset
```python
df5.head()
```

##### Bottom Values of dataset
```python
df5.tail()
```

##### Dataset Description
```python
# to get statistics for scalar values

df5.describe()
```

```python
# to get statistics for Categorical values
df5.describe(include="all")
```

##### Dataset Description
```python
df5.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   sepallength  150 non-null    float64
 1   sepalwidth   150 non-null    float64
 2   petallength  150 non-null    float64
 3   petalwidth   150 non-null    float64
 4   class        150 non-null    object 
dtypes: float64(4), object(1)
memory usage: 6.0+ KB
```

##### Columns & indexes of the data set
```python
# this is used to identify the columns in dataset
df5.columns

Index(['sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'class'], dtype='object')
```

```python
# this is used to identify the index range
df5.index
```

##### Shape of the data set
```python
# shape
df5.shape
(150, 5)
```

```python
len(df5)
150
```

#### Data Type of Columns
```python
# dtype is used to identify data type
df5["sepallength"].dtype
```
#### Separating data types in data frames
```python
# select datatype function will help to select a subeset of dataframe with float data
df5.select_dtypes(include=float)
```

```python
# select datatype function will help to select a subeset of dataframe with object data
df5.select_dtypes(include=object)
```

```python
# select datatype function will help to select a subeset of dataframe with multiple datatype in list
df5.select_dtypes(include=[float,int])
```

#### Creating data frames using Excel files
```python
df6= pd.read_excel("D:\\\\Studies\\Workshops\\\\Datascience Workshop\\\\Studies\\\\Dataset\\\\iris.xlsx")
df7=pd.ExcelFile("D:\\\\Studies\\Workshops\\\\Datascience Workshop\\\\Studies\\\\Dataset\\\\iris.xlsx")
```
#### Accessing columns & elements
```python
#
df=pd.DataFrame({"Col1":[12,22,23,34,45],
				 "Col2":[45,43,44,46,54],
				 "Col3":[56,43,46,67,65]})
df
# output
Col1	Col2	Col3
0	12	45	56
1	22	43	43
2	23	44	46
3	34	46	67
4	45	54	65
```
#### Accessing columns
```python
# Accessing a single column
df["Col1"]

# output
0    12
1    22
2    23
3    34
4    45
```
#### Adding New columns
```python
# Creating dataframe
df=pd.DataFrame({"Col1":[12,22,23,34,45],
				 "Col2":[45,43,44,46,54],
				 "Col3":[56,43,46,67,65]})
				 
df["Col4"]=[23,45,67,34,22]
df

# output
Col1	Col2	Col3	Col4
0	12	45	56	23
1	22	43	43	45
2	23	44	46	67
3	34	46	67	34
4	45	54	65	22
```

```python
df["Col5"]=[2,34,56,7,2]
df

# output
Col1	Col2	Col3	Col4	Col5
0	12	45	56	23	2
1	22	43	43	45	34
2	23	44	46	67	56
3	34	46	67	34	7
4	45	54	65	22	2
```
#### Accessing Elements
```python
# dataframe
df=pd.DataFrame({"Col1":[12,22,23,34,45],
				 "Col2":[45,43,44,46,54],
				 "Col3":[56,43,46,67,65]})
df

# output
Col1	Col2	Col3
0	12	45	56
1	22	43	43
2	23	44	46
3	34	46	67
4	45	54	65
```

```python
# df.iloc
# df.iloc[column,rows] # works with zero index
df.iloc[1,2] => 43
```

```python
# we can access to get certain section of rows and column
df.iloc[1:4,1:]

# output
Col2	Col3
1	43	43
2	44	46
3	46	67
```

```python
# df.iat
# df.iat[rows,Column] zero index
df.iat[2,2] => 46
```

iat can be use only for single elements

```python
# df.loc
# you can access the columns with name
df.loc[0,"Col2"] => 45
```

```python
# you can access the columns with name
df.loc[0:4,"Col2"]

# output
0    45
1    43
2    44
3    46
4    54
Name: Col2, dtype: int64
```

```python
# df.at
# you can access the columns with name
df.at[0,"Col2"]
```

#### Converting to Arrays

```python
# DataFrame
df=pd.DataFrame({"Col1":[12,22,23,34,45],"Col2":[45,43,44,46,54],"Col3":[56,43,46,67,65]})
df["Col1"].values
array([12, 22, 23, 34, 45], dtype=int64)
```

#### Basic Column operations
```python
data = np.arange(10).reshape(5,2)
df = pd.DataFrame(data,columns=["Col1","Col2"])
df
```

```python

df["Col3"] = df["Col1"] + df["Col2"] 
df

# output
Col1	Col2	Col3
0	0	1	1
1	2	3	5
2	4	5	9
3	6	7	13
4	8	9	17
```

```python
# creating a column on if function
df["Col4"] = ["A" if val>4 else "B" for val in df["Col3"]]
df

# output
Col1	Col2	Col3	Col4
0	0	1	1	B
1	2	3	5	A
2	4	5	9	A
3	6	7	13	A
4	8	9	17	A
```

#### Pandas Data Frame with apply functions

```python
# Dataframe
data = np.arange(10).reshape(5,2)
df = pd.DataFrame(data,columns=["Col1","Col2"])
df

# output
Col1	Col2
0	0	1
1	2	3
2	4	5
3	6	7
4	8	9
```

```python
# Applying the data frame function to calculate sum
df.apply(sum,axis=0) # Axis=0 is column wise

# output
Col1    20
Col2    25
dtype: int64
```

```python
# Applying the data frame function to calculate sum
df.apply(sum,axis=1) # Axis=1 is Row wise

# output
0     1
1     5
2     9
3    13
4    17
dtype: int64
```

```python
# Applying the data frame function to calculate mean
df.apply(np.mean,axis=0)

# output
Col1    4.0
Col2    5.0
dtype: float64
```

```python
# Applying the data frame function to calculate median
df.apply(np.median,axis=0)

# output
Col1    4.0
Col2    5.0
dtype: float64
```

```python
# creating function exponent multiplication in list
def fun2(L):
    H = [i*i for i in L]
    return sum(H)

# Applying the data frame function
df.apply(fun2,axis=0) # The function will be applied for columns

# output
Col1    120
Col2    165
dtype: int64
```

#### Pandas data frames with map function
```python
# Dataframe
data = np.arange(10).reshape(5,2)
df = pd.DataFrame(data,columns=["Col1","Col2"])

# create lambda functions multiply by 2 all the values in arrays 
fun=lambda x: 2*x

# create a column which maps values based on function
df["Col3"]=df["Col2"].map(fun)
df

# output
Col1	Col2	Col3
0	0	1	2
1	2	3	6
2	4	5	10
3	6	7	14
4	8	9	18
```

#### Selecting Rows that have certain values

#### Boolean Masking Techniques

```python
# DataFrame 
df=pd.DataFrame({"Name":["A","B","C","D","E","F"],
				 "Age":[23,33,21,35,23,34],
				 "Result":["Pass","Fail","Pass","Pass","Fail","Fail"]})
df

# output
Name	Age	Result
0	A	23	Pass
1	B	33	Fail
2	C	21	Pass
3	D	35	Pass
4	E	23	Fail
5	F	34	Fail
```

```python
# Create a subset based on the people with "pass" on results 
df[df["Result"]=="Pass"]

# output
Name	Age	Result
0	A	23	Pass
2	C	21	Pass
3	D	35	Pass
```

```python
# Create a subset based on the people with age less than or equal 30
df[df["Age"]>=30]

# output
Name	Age	Result
1	B	33	Fail
3	D	35	Pass
5	F	34	Fail
```

```python
# create a subset with multiple conditions with and function
df[((df["Result"]=="Pass") & (df["Age"]>=30))]

# output
Name	Age	Result
3	D	35	Pass 
```

```python
# create a subset of people who are not passed
df[~(df["Result"]=="Pass")]

# output
Name	Age	Result
1	B	33	Fail
4	E	23	Fail
5	F	34	Fail
```

#### Selecting with Map Functions
```python
# create a function for filter all the passed
fun = lambda L:  "Pass" in L

# creating a subset of people who are passed using map function
df[df["Result"].map(fun)]
# output
Name	Age	Result
0	A	23	Pass
2	C	21	Pass
3	D	35	Pass
```

```python
# create a function for filter people age greater than or equal
fun2 = lambda L: L>=30

# creating a subset of people who are passed using map function
df[df["Age"].map(fun2)]

# output
Name	Age	Result
1	B	33	Fail
3	D	35	Pass
5	F	34	Fail
```

#### Pandas Queries
```python
# Query should be given as a string in Query
df.query('Result=="Pass"') # a practice better to give

# output
Name	Age	Result
0	A	23	Pass
2	C	21	Pass
3	D	35	Pass
```

```python
# Query should be given as a string in Query
df.query('Age>=30')

# output
Name	Age	Result
1	B	33	Fail
3	D	35	Pass
5	F	34	Fail
```

```python
# Query should be given as a string in Query
df.query('Result=="Pass" and Age>=30')

Name	Age	Result
3	D	35	Pass
```

#### Data Summaries
```python
# Random Data
data=np.random.random(10).round(2).reshape(5,2)
# Dataset
df=pd.DataFrame(data,columns=["A","B"],index=["a","b","c","d","e"])
df

# output
A	B
a	0.64	0.77
b	0.25	0.31
c	0.05	0.31
d	0.11	0.67
e	0.01	0.96
```

#### Summaries for each columns
```python
# geting summaries for each columns
df.describe()

# output

A	B
count	5.000000	5.000000
mean	0.212000	0.604000
std	0.255969	0.287889
min	0.010000	0.310000
25%	0.050000	0.310000
50%	0.110000	0.670000
75%	0.250000	0.770000
max	0.640000	0.960000
```

### Summaries for each Rows

```python
# to get summary for each rows first transpose the rows to columns and then we can perform summaries
df.transpose().describe()

# output
a	b	c	d	e
count	2.000000	2.000000	2.000000	2.00000	2.000000
mean	0.705000	0.280000	0.180000	0.39000	0.485000
std	0.091924	0.042426	0.183848	0.39598	0.671751
min	0.640000	0.250000	0.050000	0.11000	0.010000
25%	0.672500	0.265000	0.115000	0.25000	0.247500
50%	0.705000	0.280000	0.180000	0.39000	0.485000
75%	0.737500	0.295000	0.245000	0.53000	0.722500
max	0.770000	0.310000	0.310000	0.67000	0.960000
```

#### To get summaries for categorical Columns
```python
# dataset
df=pd.DataFrame({"A":[23,34,21,45,67],"B":[45,24,67,88,67],"C":["a","a","b","b","a"]})
df.describe(include="all")

# output
A	B	C
count	5.000000	5.000000	5
unique	NaN	NaN	2
top	NaN	NaN	a
freq	NaN	NaN	3
mean	38.000000	58.200000	NaN
std	18.841444	24.427444	NaN
min	21.000000	24.000000	NaN
25%	23.000000	45.000000	NaN
50%	34.000000	67.000000	NaN
75%	45.000000	67.000000	NaN
max	67.000000	88.000000	NaN
```

#### Dropping Rows and Columns

##### Dropping Rows
```python
# Dataframe
df=pd.DataFrame({"Name":["A","B","C"],"Age":[23,33,21],"Result":["Pass","Fail","Pass"]},index=["a","b","c"])
df

# output
Name	Age	Result
a	A	23	Pass
b	B	33	Fail
c	C	21	Pass
```

```python
# to drop a rows we need to give the index that has been assigned to
df.drop("b")

# output
Name	Age	Result
a	A	23	Pass
c	C	21	Pass
```

```python
# to save the change in dataframe
df.drop("b", inplace=True)
df

# output
Name	Age	Result
a	A	23	Pass
c	C	21	Pass
```
##### Dropping Columns
```python
# dataset
df=pd.DataFrame({"Name":["A","B","C"],"Age":[23,33,21],"Result":["Pass","Fail","Pass"]},index=["a","b","c"])
df

# output
Name	Age	Result
a	A	23	Pass
b	B	33	Fail
c	C	21	Pass
```

```python
df.drop("Age",axis=1) # by default the axis will be zero for rows

# Output
Name	Result
a	A	Pass
b	B	Fail
c	C	Pass
```

```python
# to save the change in dataframe
df.drop("Age",axis=1, inplace=True)
df

# Output
Name	Result
a	A	Pass
b	B	Fail
c	C	Pass
```

```python
# to remove multiple columns
df.drop(["Age", "Name"],axis=1)

# Output

Result
a	Pass
b	Fail
c	Pass
```

### Sorting Dataframes with Column values

```python
# dataset
d={"Name":["Sam","Jane","Kane"],"Mark1":[67,54,44],"Mark2":[56,56,67],"Mark3":[78,89,76]}
df=pd.DataFrame(d)
df

# output

Name	Mark1	Mark2	Mark3
0	Sam	67	56	78
1	Jane	54	56	89
2	Kane	44	67	76
```

```python
# ascending order
df.sort_values(by="Mark1")

# output
Name	Mark1	Mark2	Mark3
2	Kane	44	67	76
1	Jane	54	56	89
0	Sam	67	56	78
```

```python
# Decending order
df.sort_values(by="Mark1", ascending=False)

# output
Name	Mark1	Mark2	Mark3
0	Sam	67	56	78
1	Jane	54	56	89
2	Kane	44	67	76
```

#### Grouping Data Frames with Categorical Data
```python
# dataset
d={"ID":[1001,1002,1003,1004,1005],"Age":[23,33,34,24,25],"Gender":["F","F","M","F","M"],"Marks":[67,69,76,74,90]}
df=pd.DataFrame(d)
df

# output
ID	Age	Gender	Marks
0	1001	23	F	67
1	1002	33	F	69
2	1003	34	M	76
3	1004	24	F	74
4	1005	25	M	90
```

```python
# creating a groupby
groups = df.groupby("Gender")
list(groups)

# output
[('F',
       ID  Age Gender  Marks
  0  1001   23      F     67
  1  1002   33      F     69
  3  1004   24      F     74),
 ('M',
       ID  Age Gender  Marks
  2  1003   34      M     76
  4  1005   25      M     90)]
```

#### Get a Specific Group

```python
df.groupby("Gender").get_group("M")

# output
ID	Age	Gender	Marks
2	1003	34	M	76
4	1005	25	M	90
```

#### Summaries for other Variables with grouping

```python
df.groupby("Gender").mean()

# Output
ID	Age	Marks
Gender			
F	1002.333333	26.666667	70.0
M	1004.000000	29.500000	83.0
```

#### Summarizing other variables with grouping by using multiple options

```python
df.groupby("Gender").agg(["mean","median","sum", "min", "max"])

# output
ID	Age	Marks
mean	median	sum	min	max	mean	median	sum	min	max	mean	median	sum	min	max
Gender															
F	1002.333333	1002.0	3007	1001	1004	26.666667	24.0	80	23	33	70.0	69.0	210	67	74
M	1004.000000	1004.0	2008	1003	1005	29.500000	29.5	59	25	34	83.0	83.0	166	76	90
```

#### Grouping with one or More Columns
```python
d={"Age":[23,33,34,24,25],"Gender":["F","F","M","F","M"],"Marks":[67,69,76,74,90],"University":["UOC","UOC","UOC","UOP","UOP"]}
df=pd.DataFrame(d)
df
# output
Age	Gender	Marks	University
0	23	F	67	UOC
1	33	F	69	UOC
2	34	M	76	UOC
3	24	F	74	UOP
4	25	M	90	UOP
```

```python
list(df.groupby(["Gender", "University"]))

# output

[(('F', 'UOC'),
     Age Gender  Marks University
  0   23      F     67        UOC
  1   33      F     69        UOC),
 (('F', 'UOP'),
     Age Gender  Marks University
  3   24      F     74        UOP),
 (('M', 'UOC'),
     Age Gender  Marks University
  2   34      M     76        UOC),
 (('M', 'UOP'),
     Age Gender  Marks University
  4   25      M     90        UOP)]
```

```python
df.groupby(["Gender", "University"]).agg(["mean", "median","sum", "min", "max"])

# output
Age	Marks
mean	median	sum	min	max	mean	median	sum	min	max
Gender	University										
F	UOC	28.0	28.0	56	23	33	68.0	68.0	136	67	69
UOP	24.0	24.0	24	24	24	74.0	74.0	74	74	74
M	UOC	34.0	34.0	34	34	34	76.0	76.0	76	76	76
UOP	25.0	25.0	25	25	25	90.0	90.0	90	90	90
```

#### Concatenating Data Frame
```python
# Creating multiple dataset
df1=pd.DataFrame(np.random.random((5,2)),columns=["A","B"])
df2=pd.DataFrame(np.random.random((5,2)),columns=["A","B"])
df3=pd.DataFrame(np.random.random((5,2)),columns=["C","D"])
```

```python
## Concatenating along the columns
df4=pd.concat([df1,df3],axis=1)
df4

output
A	B	C	D
0	0.055350	0.151484	0.526927	0.126318
1	0.352571	0.756687	0.223020	0.349496
2	0.983828	0.240636	0.963283	0.363161
3	0.118841	0.592184	0.037554	0.904814
4	0.676238	0.405871	0.517918	0.556828
```

```python
# concatnating along the rows
df4=pd.concat([df1,df2], ignore_index=True)
df4

output:
A	B
0	0.055350	0.151484
1	0.352571	0.756687
2	0.983828	0.240636
3	0.118841	0.592184
4	0.676238	0.405871
5	0.670672	0.404303
6	0.645923	0.750909
7	0.309454	0.068446
8	0.236489	0.494636
9	0.692216	0.699760
```

### Merging Dataframe

```python
## Dataset
df1=pd.DataFrame({"ID":[1,2,3,4],"Val1":[23,33,34,45]})
df2=pd.DataFrame({"ID":[3,4,5,6],"Val2":[56,32,67,65]})
```

#### Focus on common Ids

```python
# we can use Pd.merge with by combining using id column and method =inner
# this will provide merge for common ids

pd.merge(df1,df2,on="ID",how="inner")

output
ID	Val1	Val2
0	3	34	56
1	4	45	32
```

#### Focus on the all the ids

```python
# we can use Pd.merge with by combining using id column and method =outer
# this will provide merge for all ids
# provides np.nan for missing values
pd.merge(df1,df2,on="ID",how="outer")

output
ID	Val1	Val2
0	1	23.0	NaN
1	2	33.0	NaN
2	3	34.0	56.0
3	4	45.0	32.0
4	5	NaN	67.0
5	6	NaN	65.0
```

#### Focus on the left side data frame Ids

```python
# we can use Pd.merge with by combining using id column and method =left
# only matches the left ids
pd.merge(df1,df2,on="ID",how="left")

output

ID	Val1	Val2
0	1	23	NaN
1	2	33	NaN
2	3	34	56.0
3	4	45	32.0
```

#### Focus on the right side data frame Ids

```python
# we can use Pd.merge with by combining using id column and method =left
# only matches the left ids
pd.merge(df1,df2,on="ID",how="right")

output:
ID	Val1	Val2
0	3	34.0	56
1	4	45.0	32
2	5	NaN	67
3	6	NaN	65

```

#### Using an indicator for showing how the tables are merged

```python
pd.merge(df1,df2,on="ID",how="right",indicator=True)

output
ID	Val1	Val2	_merge
0	3	34.0	56	both
1	4	45.0	32	both
2	5	NaN	67	right_only
3	6	NaN	65	right_only
```

### **Merging based on more than one column**

```python
df1=pd.DataFrame({"ID1":[1,2,3,4],"ID2":[7,8,9,10],"Val1":[23,33,34,45]})
df2=pd.DataFrame({"ID1":[2,3,5,6],"ID2":[8,9,10,11],"Val2":[56,32,67,65]})

pd.merge(df1,df2,on=["ID1","ID2"],how="outer")

output
ID1	ID2	Val1	Val2
0	1	7	23.0	NaN
1	2	8	33.0	56.0
2	3	9	34.0	32.0
3	4	10	45.0	NaN
4	5	10	NaN	67.0
5	6	11	NaN	65.0
```

### Counting Values

```python
d={"Col1":["P","P","Q"],"Col2":["X","Y","Z"],"Col3":["A","B","C"]}
df=pd.DataFrame(d)
df

pd.value_counts(df["Col1"])

P    2
Q    1
Name: Col1, dtype: int64
```

### Unique Values in a columns

```python
d={"Col1":["P","P","Q"],"Col2":["X","Y","Z"],"Col3":["A","B","C"]}
df=pd.DataFrame(d)
df

df["Col1"].unique()
output
array(['P', 'Q'], dtype=object)
```

#### Stacking & Unstacking Data frame

```python

df.stack()
0  Col1    P
   Col2    X
   Col3    3
1  Col1    P
   Col2    Y
   Col3    6
2  Col1    Q
   Col2    Z
   Col3    8
dtype: object
```

```python
df.unstack()

Col1  0    P
      1    P
      2    Q
Col2  0    X
      1    Y
      2    Z
Col3  0    3
      1    6
      2    8
dtype: object
```

#### Creating a Pivot Tables

```python
# data Frame
d={"Cat":["A","B","B","A","C","A","C","B"],"Rank":["1","2","1","2","1","2","1","2"],"Val":[4,5,6,8,3,9,8,2]}
df=pd.DataFrame(d)
df
```

```python
df.pivot_table(index=["Cat","Rank"], aggfunc="mean")

output
Val
Cat	Rank	
A	1	4.0
2	8.5
B	1	6.0
2	3.5
C	1	5.5
```

```python
df.pivot_table(index=["Cat","Rank"], aggfunc="sum")
Val
Cat	Rank	
A	1	4
2	17
B	1	6
2	7
C	1	11
```

#### Binning

```python
# Dataframe
d={"ID":[1001,1002,1003,1004,1005],"Marks":[78,88,45,67,59]}
df=pd.DataFrame(d)
df
```

```python
# use pd.cut for binning
df["Grades"] = pd.cut(df["Marks"],[0,50,65,80,100], labels=["F","C","B","A"])
df["Grades"]

output:
0    B
1    A
2    F
3    B
4    C
Name: Grades, dtype: category
Categories (4, object): ['F' < 'C' < 'B' < 'A']
```

#### Largest and smallest values in a column

```python
# dataframe
d={"Cat":["A","B","B","A","C","A","C","B"],"Rank":["1","2","1","2","1","2","1","2"],"Val":[4,5,6,8,3,9,8,2]}
df=pd.DataFrame(d)
df
```

```python
# showing the largest values
df.nlargest(1,"Val")

output
Cat	Rank	Val
5	A	2	9
```

```python
# showing the smallest value
df.nsmallest(1,"Val")

output
Cat	Rank	Val
7	B	2	2
```

#### Working with indexes & columns
```python
# Dataset
d={"Name":["Sam","Pam","Jane"],"Marks":[56,32,78],"Class":[1,2,3]}
df=pd.DataFrame(d,index=["a","b","c"])
df
output:
Name	Marks	Class
a	Sam	56	1
b	Pam	32	2
c	Jane	78	3
```